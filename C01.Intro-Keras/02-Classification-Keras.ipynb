{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "877d17af-9b93-4534-8163-2adf7dc490e7"
      },
      "source": [
        "<h1 align=center><font size = 5>Classification Models with Keras</font></h1>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "889d50b2-1117-400d-8850-1678e63f207f"
      },
      "source": [
        "## Table of Contents\n",
        "\n",
        "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
        "\n",
        "<font size = 3>\n",
        "\n",
        "1. <a href=\"#item312\">Import Keras and Packages</a>      \n",
        "2. <a href=\"#item322\">Build a Neural Network</a>     \n",
        "3. <a href=\"#item332\">Train and Test the Network</a>     \n",
        "\n",
        "</font>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04cb5309-8b73-4ee3-bc33-6f98e6c6d5ea"
      },
      "source": [
        "## Import Keras and Packages\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83b22757-26ef-4bd1-a2c6-6144f6c843a7"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4d8f324-7a70-4f0d-85f1-fe396b6f8cc4"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7033ea0-c156-4a14-accf-180e26b6ea42",
        "outputId": "b2bf4539-e235-4fa9-ad40-f20f23f0538b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "# import the data\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# read the data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73e7608c-3f34-4651-b8c5-51654400f8a1",
        "outputId": "b7e1c166-10fe-472c-c72f-dbfe1967cb81"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "X_train.shape"
      ],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5b7c56a-4f99-476e-be99-0646b13d4d02"
      },
      "source": [
        "Let's visualize the first image in the training set using Matplotlib's scripting layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "1c672f04-f79d-4354-835d-40cce8035e53",
        "outputId": "79bc132c-ad2e-40f3-dd7d-7cde0ecb3afa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x78e4d7544650>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 200x200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(2,2))\n",
        "plt.imshow(X_train[0])"
      ],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b400ce0-07a1-4fd8-ae7c-7fd8d8bb701f"
      },
      "outputs": [],
      "source": [
        "# flatten images into one-dimensional vector\n",
        "\n",
        "num_pixels = X_train.shape[1] * X_train.shape[2] # find size of one-dimensional vector\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32') # flatten training images\n",
        "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32') # flatten test images"
      ],
      "execution_count": 11
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41d73cc8-9523-4df9-b2f0-4161172cd85b"
      },
      "source": [
        "Since pixel values can range from 0 to 255, let's normalize the vectors to be between 0 and 1.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "423fbf2a-6f56-4d14-8d78-5c794ef0d977"
      },
      "outputs": [],
      "source": [
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255"
      ],
      "execution_count": 12
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6578c204-30db-402a-af8d-3a25b181e9fb"
      },
      "source": [
        "Finally, before we start building our model, remember that for classification we need to divide our target variable into categories. We use the to_categorical function from the Keras Utilities package.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2cf1708-ab81-4055-ba61-796ea2305f71",
        "outputId": "3af42c9c-f885-409b-e45b-9cfd468d4977"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ],
      "source": [
        "# one hot encode outputs\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "num_classes = y_test.shape[1]\n",
        "print(num_classes)"
      ],
      "execution_count": 13
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c45ab845-8ed9-45c1-ab98-f0b459336211"
      },
      "source": [
        "## Build a Neural Network\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fda3388-0933-4cb8-876b-b390b8a3fcd5"
      },
      "outputs": [],
      "source": [
        "# define classification model\n",
        "def classification_model():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(num_pixels, activation='relu', input_shape=(num_pixels,)))\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    # compile model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 14
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbc54f7f-b0bc-4af6-ab8f-8ffba65d56e8"
      },
      "source": [
        "## Train and Test the Network\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7c3ce34a-7d96-4b73-a9d6-a3e6a24b584f"
      },
      "outputs": [],
      "source": [
        "# build the model\n",
        "model = classification_model()\n",
        "\n",
        "# fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, verbose=2)\n",
        "\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "## output:\n",
        "# Epoch 10/10\n",
        "# 1875/1875 - 43s - 23ms/step - accuracy: 0.9952 - loss: 0.0154 - val_accuracy: 0.9796 - val_loss: 0.0997"
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7346129-0871-4ed8-a0f9-d60b4a031436"
      },
      "source": [
        "Let's print the accuracy and the corresponding error.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ca30118-1d39-475d-9282-fd94a063fe2b",
        "outputId": "92cd07c8-f340-4963-b030-851d7e9826eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9796000123023987% \n",
            " Error: 0.02039998769760132\n"
          ]
        }
      ],
      "source": [
        "print('Accuracy: {}% \\n Error: {}'.format(scores[1], 1 - scores[1]))"
      ],
      "execution_count": 16
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "988683a0-ba7b-4b83-8c02-248a9b6af698"
      },
      "source": [
        "Sometimes, you cannot afford to retrain your model everytime you want to use it, especially if you are limited on computational resources and training your model can take a long time. Therefore, with the Keras library, you can save your model after training. To do that, we use the save method.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c72b31e3-98ce-477f-a0f9-e12539e9296c",
        "outputId": "92dde8b2-0d53-4f83-df7d-0dc430307083"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "model.save('classification_model.h5')"
      ],
      "execution_count": 17
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c002e07-6613-4216-8592-d0bb380c158d"
      },
      "source": [
        "When you are ready to use your model again, you use the load_model function from <strong>keras.models</strong>.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f565995e-4175-475c-96fc-87de6803dd66"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model"
      ],
      "execution_count": 18
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de31ca51-19f9-4fc7-b059-6aaefc697827",
        "outputId": "151e83b3-83a3-4d76-c3d5-2dae10ac5da6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "pretrained_model = load_model('classification_model.h5')"
      ],
      "execution_count": 19
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python",
      "language": "python",
      "name": "conda-env-python-py"
    },
    "language_info": {
      "name": ""
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}